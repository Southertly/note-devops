# kafka高可用原理

参考文章

1. [Kafka学习之路 （三）Kafka的高可用](https://www.cnblogs.com/qingyunzong/p/9004703.html)
    - producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition
2. [kafka partition分配_震惊了！原来这才是 Kafka！（多图+深入）](https://blog.csdn.net/weixin_42310891/article/details/112264408)
    - 全面
    - 第1张图, topic0分为2个分区, 每个分区有3个副本(一主两从).
    - 同一个消费组中的两个消费者, 不会消费同一个partition
    - 关于`offset`的解释, 很详细
3. [「Kafka深度解析」快速入门](https://www.jianshu.com/p/da1222dd0d32)
    - kafka特性
    - kafka核心概念
    - kafka**消费者**在会保存其消费的进度, 也就是offset
4. [Java工程师的进阶之路 Kafka篇（一）](https://www.jianshu.com/p/cbf684893574)
    - 消息系统存在必要性: 解耦, 冗余, 扩展性, 灵活性&峰值处理能力, 可恢复性, 顺序保证, 缓冲, 异步通信
    - ~~名词概念的解释并不是很清晰~~
    - 设计思想(很不错)
    - 应用场景(不错)
    - Push 模式 vs Pull 模式(非常不错!)
5. [kafka partition（分区）与 group](https://www.cnblogs.com/liuwei6/p/6900686.html)
    - 对于传统的message queue而言, 一般会删除已经被消费的消息, 而Kafka集群会保留所有的消息, 无论其被消费与否. 
    - 当然, 因为磁盘限制, 不可能永久保留所有数据（实际上也没必要）, 因此Kafka提供两种策略删除旧数据. 一是基于时间, 二是基于Partition文件大小. 
    - Kafka读取特定消息的时间复杂度为O(1), 即与文件大小无关, 所以这里删除过期文件与提高Kafka性能无关. 选择怎样的删除策略只与磁盘以及具体的需求有关

消息系统中按`topic`进行发布订阅是比较常见的解决方案, 这里不再解释`topic`的概念.

## 分片与副本

kafka 的分片与副本机制与 redis cluster 模式很相似, 将数据进行分片存储提高容量与吞吐, 每个分片也可以设置多个副本进行灾备.

不同的是, redis cluster 的副本是可读但不可写, 而 kafka 的副本则是读写都不可以, 即客户端读写的**只有主分片**.

双方各有优势, 前者性能更高, 但是主从节点间数据同步必然存在延迟, 客户端有可能读到旧数据或过期数据;

### 分片的部署策略

1. 一个Topic的Partition数量大于Broker的数量, 即每个 Broker 都保存一个分片;
2. 同一个Partition的Replica尽量分散到不同的 broker;

> kafka 的应用场景中数据量巨大, 需要做好消息轮替的时间配置, 让过期的消息及时被清理.

Kafka分配Replica的算法如下：

1. 将所有Broker（假设共n个Broker）和待分配的Partition排序
2. 将第i个Partition分配到第（i % n）个Broker上
3. 将第i个Partition的第j个Replica分配到第（(i + j) % n）个Broker上

其实这个分配逻辑是很简单的(不知道是不是做了简化), 对于一个3节点的kafka集群, 一个3分片2副本的Topic, ta的分配方式差不多是这样的:

| Broker-0 | Broker-1 | Broker-2 |
| :------- | :------- | :------- |
| P1       | R11      | R12      |
| R22      | P2       | R21      |
| R31      | R32      | P3       |

但这其实也带来一个问题.

### 关于消费

假设存在一个`topic`, 其全部内容为: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], 在一个3主机的kafka集群中, kafka可以将些`topic`划分为3个分片, 每台主机拥有1个分片.

- topic-0: [1, 3, 7, 10]
- topic-1: [2, 5, 9, 12, 13]
- topic-2: [4, 6, 8, 11]

kafka 在写入时均衡地将数据分散到不同分片中存储(提高吞吐量与容量), 这样只能保证同一分片中的消费是有序的.

消费者在消费时保存的消费记录 offset 只是针对分片的, 比如在消费 topic-0 时, 如果取走了[1, 3, 7], 那 offset 就变成了 4, 接下来取走的就是"10".

如果某个消费组中只有1个消费者, ta需要同时消费3个分片, 有可能出现[4, 2, 1]的情况, 即不同分区同时消费时不无保证有序.

## 消费

假设消费者1, 消费者2...等, 来自不同业务系统, ta们需要处理来自同一个`topic`的消息, 且不能相互影响. 比如消费者1按顺序从`topic`取出了[1, 2, 3], 其他业务系统的消费者不能受到影响, ta们也需要[1, 2, 3]这些数据;

再考虑一下, 假设消费者1A, 消费者1B, 1C等, 属于同一个业务系统, 他们需要对`topic`同时进行处理, 如何协同才能提高效率, 又不重复消费?

这就引出了"消费组"的概念.

kafka的消费者其实都是以消费组的形式工作的, 多个消费者可以属于同一个消费组. 每一个消费组都可以获取到目标`topic`的所有数据, 而同一个消费组的不同消费者之间可以实现协同.

怎么实现的? 多个消费者处理同一个`topic`, 互相之间是怎么知道处理到哪一条数据了?

这个消费的位置称为`offset`, 具体可见参考文章1.

### 消费组

一般来说, 同一个消费组中的消费者数量, 最好等于目标`topic`的分区数量.

其实, 每当某个消费组的一个消费者启动并接入kafka时, ta就绑定到了某个分区(的`Leader`), ta之后消费的数据, 都是从这个分区上的消息.

再次借用上面的示例, 假设一个名为`ConsumerGroup1`的消费组.

1. ta的第1个消费者`consumer1A`启动时, kafka将3个分区都附加给这个消费者, 这唯一一个消费者会处理该`topic`的3个分区中的所有消息;
2. 然后第2个消费者`consumer1B`启动, kafka会将分区1, 2分配给ta, 分区0仍然留给`consumer1A`;
3. 第3个消费者`consumer1C`启动, kafka将分区2分配给ta, 此时3个消费者分别处理一个分区的数据;
4. 第4个消费者`consumer1D`启动, 但是这个`topic`已经没有多余的分区了, 所以ta将会空转...

这个过程被称为`reblance`, 具体的流程可见参考文章1.
